{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ v7.0-212-g9974d51 Python-3.8.10 torch-2.0.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "detect_model = torch.hub.load('../yolov5/', 'custom', path='../weights/detect_weights.pt', force_reload=True, source='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_color_seg(image):\n",
    "\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # lower boundary RED color range values; Hue (0 - 10)\n",
    "    lower1 = np.array([0, 120, 0])\n",
    "    upper1 = np.array([12, 255, 255])\n",
    "\n",
    "    # upper boundary RED color range values; Hue (160 - 180)\n",
    "    lower2 = np.array([160,120,0])\n",
    "    upper2 = np.array([185,255,255])\n",
    "\n",
    "    lower_mask = cv2.inRange(hsv_image, lower1, upper1)\n",
    "    upper_mask = cv2.inRange(hsv_image, lower2, upper2)\n",
    "    red_mask = lower_mask | upper_mask\n",
    "\n",
    "    red_seg = cv2.bitwise_and(image, image, mask=red_mask)\n",
    "    cv2.imwrite(\"stage1.jpg\", red_seg)\n",
    "\n",
    "\n",
    "    # dont change 5\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    red_mask = cv2.dilate(red_mask, kernel, iterations=1)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # kernel = np.ones((7, 7), np.uint8)\n",
    "\n",
    "    red_segmented_image = cv2.bitwise_and(image, image, mask=red_mask)\n",
    "    # cv2.imwrite(\"stage2.jpg\", red_segmented_image)\n",
    "    # red_segmented_image = cv2.fastNlMeansDenoisingColored(red_segmented_image, None,30,30,15,30) \n",
    "\n",
    "    gray = cv2.cvtColor(red_segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find contours in the opened maskqqqqqqqqq\n",
    "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    min_area_threshold = 0\n",
    "    max_area_threshold = 8000\n",
    "    # Filter out contours with area less than the threshold and fill them with black color\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < min_area_threshold or area > max_area_threshold:\n",
    "            cv2.drawContours(gray, [contour], 0, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    # red_mask = cv2.erode(red_mask, kernel, iterations=1)\n",
    "    red_segmented_image = cv2.bitwise_and(image, image, mask=gray)\n",
    "    # cv2.imwrite(\"stage3.jpg\", red_segmented_image)\n",
    "    # print(red_segmented_image.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # red_segmented_image = cv2.GaussianBlur(red_segmented_image, (7, 7), 0)\n",
    "    # red_segmented_image = cv2.fastNlMeansDenoisingColored(red_segmented_image, None,30,30,10,30) \n",
    "    # red_segmented_image = cv2.GaussianBlur(red_segmented_image, (5, 5), 0)\n",
    "    # image = cv2.addWeighted(image, 1, red_segmented_image, 0.5, 0)\n",
    "\n",
    "    return red_segmented_image, gray\n",
    "    # cv2.imshow(\"out\", red_segmented_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(image):\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixel_values = lab_image.reshape((-1, 3))\n",
    "\n",
    "    # Remove black pixels (where L = 0)\n",
    "    non_black_pixels = pixel_values[pixel_values[:, 0] != 0]\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    k = 5  # Number of clusters\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, centers = cv2.kmeans(np.float32(non_black_pixels), k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Initialize a mask to store clusters with enough pixels\n",
    "    mask = np.zeros_like(labels)\n",
    "\n",
    "    # Count the number of pixels in each cluster\n",
    "    for i in range(k):\n",
    "        mask[labels.ravel() == i] = np.count_nonzero(labels == i)\n",
    "\n",
    "    # Filter out clusters with fewer than a specified number of pixels\n",
    "    threshold = 100  # Minimum number of pixels per cluster\n",
    "    mask[mask < threshold] = 0\n",
    "\n",
    "    # Create a binary mask for the filtered clusters\n",
    "    filtered_mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    # Reshape the mask to the original image shape\n",
    "    filtered_mask = filtered_mask.reshape(lab_image.shape[:2])\n",
    "\n",
    "    # Apply the filtered mask to the original image\n",
    "    result = cv2.bitwise_and(image, image, mask=filtered_mask)\n",
    "\n",
    "    # Display the result\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_seg(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    circles = cv2.HoughCircles(blurred, cv2.HOUGH_GRADIENT, dp=0.1, minDist=50, param1=100, param2=40, minRadius=10, maxRadius=100)\n",
    "\n",
    "    if circles is not None:\n",
    "        circles = np.round(circles[0, :]).astype(\"int\")\n",
    "        for (x, y, r) in circles:\n",
    "            cv2.circle(image, (x, y), r, (0, 255, 0), 4)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tria_seg(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate through contours and approximate them to identify triangles\n",
    "    for contour in contours:\n",
    "        # Approximate the contour to a polygon\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n",
    "\n",
    "        # If the approximated polygon has 3 vertices, it's a triangle\n",
    "        if len(approx) == 3:\n",
    "            cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture('/home/ashmitha/traffic_sign_detection/test_images/sunlight_straight.mkv')\n",
    "\n",
    "# frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "# print(frame_rate)\n",
    "\n",
    "# # Calculate the new frame rate (double the original frame rate)\n",
    "# new_frame_rate = frame_rate * 10\n",
    "\n",
    "# # Set the new frame rate for the video capture\n",
    "# video_capture.set(cv2.CAP_PROP_FPS, new_frame_rate)\n",
    "# frame_rate = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "# print(frame_rate)\n",
    "\n",
    "detection_data = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_correct = 0\n",
    "detected_wrong = 0\n",
    "did_not_detect = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    detected_correct += int(input(\"Enter the number of true positives: \"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['prohibitory', 'danger', 'mandatory', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Read the next frame\n",
    "    ret, frame = video_capture.read()\n",
    "    # cv2.imshow(\"out\", frame)\n",
    "\n",
    "    frame_copy = frame.copy()\n",
    "    \n",
    "    seg_frame, mask = red_color_seg(frame)\n",
    "\n",
    "    results = detect_model(frame)\n",
    "\n",
    "    bounding_boxes = results.xyxy[0].cpu().numpy()\n",
    "    cv2.putText(frame_copy, str(video_capture.get(cv2.CAP_PROP_POS_MSEC)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    for box in bounding_boxes:\n",
    "        x_min, y_min, x_max, y_max, confidence, class_id = box\n",
    "\n",
    "        if not mask[int(y_min):int(y_max), int(x_min):int(x_max)].any():\n",
    "            confidence = confidence * 0.5\n",
    "\n",
    "        if  confidence > 0.4:\n",
    "            cv2.putText(frame_copy, str(confidence), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "            cv2.rectangle(frame_copy, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "            class_ = classes[int(class_id)]\n",
    "            detection_data.append([video_capture.get(cv2.CAP_PROP_POS_MSEC), class_, confidence])\n",
    "\n",
    "    # for box in bounding_boxes:\n",
    "    #     x_min, y_min, x_max, y_max, confidence, class_id = box\n",
    "    #     if confidence > 0.4:\n",
    "    #         cv2.rectangle(frame_copy, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "    concatenated_frame = cv2.hconcat([frame, seg_frame])\n",
    "\n",
    "\n",
    "    # Display the concatenated frame\n",
    "    cv2.imshow(\"Original vs Processed\", frame_copy)\n",
    "    \n",
    "\n",
    "    # # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord('n'):\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord('s'):\n",
    "        detection_data.append([\"start frame\",video_capture.get(cv2.CAP_PROP_POS_MSEC), ])\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == ord('e'):\n",
    "        detection_data.append([\"end frame\",video_capture.get(cv2.CAP_PROP_POS_MSEC), ])\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "   \n",
    "\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(detection_data, columns=['Timestamp', 'ClassID', 'Confidence'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('dark_sign.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('plot.csv', header=None)\n",
    "\n",
    "# Extract the first and last numerical values\n",
    "first_value = df.iloc[:,0]\n",
    "last_value = df.iloc[:,2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(first_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = [\n",
    "    (96468.0, 'x', 0.0),\n",
    "    (98001.0, 'prohibitory', 0.4190042316913605),\n",
    "    (98334.0, 'danger', 0.4456574022769928),\n",
    "    (99468.0, 'mandatory', 0.5257366299629211),\n",
    "    (99534.0, 'mandatory', 0.6467638611793518),\n",
    "    (99601.0, 'mandatory', 0.43351343274116516),\n",
    "    (99668.0, 'mandatory', 0.7146356701850891),\n",
    "    (99734.00000000001, 'mandatory', 0.5248815417289734),\n",
    "    (99801.0, 'mandatory', 0.5179475545883179),\n",
    "    (99801.0, 'prohibitory', 0.46880823373794556),\n",
    "    (99868.0, 'prohibitory', 0.4657275676727295),\n",
    "    (99934.0, 'mandatory', 0.47248154878616333),\n",
    "    (100068.0, 'prohibitory', 0.5615005493164062),\n",
    "    (100201.00000000001, 'prohibitory', 0.616981565952301),\n",
    "    (100268.0, 'other', 0.468959242105484),\n",
    "    (100334.0, 'other', 0.5272660255432129),\n",
    "    (100401.0, 'prohibitory', 0.8893968462944031),\n",
    "    (100468.0, 'other', 0.4021945893764496),\n",
    "    (100601.0, 'other', 0.563284695148468),\n",
    "    (100668.0, 'other', 0.5965499877929688),\n",
    "    (100934.0, 'other', 0.44282960891723633),\n",
    "    (101068.0, 'prohibitory', 0.7431638240814209)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Extract x and y values\n",
    "x_values = [item[0] for item in data]\n",
    "y_values = [item[2] for item in data]\n",
    "\n",
    "# Plot the arrays against each other\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x_values, y_values, marker='o', linestyle='-')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Plot of Values against Timestamp')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the value\n",
    "# plt.figure(figsize=(8, 6))\n",
    "plt.plot([np.array(first_value), np.array(last_value)], marker='o', color='blue')\n",
    "plt.xlabel('First Value')\n",
    "plt.ylabel('Last Value')\n",
    "plt.title('Plot of First vs Last Numerical Value')\n",
    "# plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/home/ashmitha/traffic_sign_detection/test_images/test1.jpg\")\n",
    "\n",
    "img = red_color_seg(img)\n",
    "img = circle_seg(img)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/home/ashmitha/traffic_sign_detection/scripts/x.jpg\")\n",
    "cv2.imshow(\"Image\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the input image\n",
    "image = cv2.imread(\"../scripts/x.jpg\")  # Replace \"triangle_image.jpg\" with the path to your image\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur to reduce noise\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Detect edges using Canny edge detection\n",
    "edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find contours in the edge-detected image\n",
    "contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through contours and approximate them to identify triangles\n",
    "for contour in contours:\n",
    "    # Approximate the contour to a polygon\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)\n",
    "\n",
    "    print(len(approx))\n",
    "    # If the approximated polygon has 3 vertices, it's a triangle\n",
    "    if len(approx) == 8:\n",
    "        print(\"reached\")\n",
    "        cv2.drawContours(image, [approx], -1, (0, 255, 0), 2)\n",
    "\n",
    "# # Display the result\n",
    "cv2.imshow(\"Triangles Detected\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../data/GTSDB/train_detection/images/\"\n",
    "test_images = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"00298.jpg\"\n",
    "img = cv2.imread(path + image_path)\n",
    "og_img = img.copy()\n",
    "\n",
    "cv2.imshow(\"og\", img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = red_color_seg(img)\n",
    "\n",
    "# cir_img = circle_seg(img.copy())\n",
    "# tria_img = tria_seg(img.copy())\n",
    "# cv2.imwrite(\"circle.jpg\", cir_img)\n",
    "# cv2.imwrite(\"tria.jpg\", tria_img)\n",
    "# results_image = np.hstack((tria_img, cir_img, og_img))\n",
    "# image_rgb = cv2.cvtColor(results_image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"Side by Side\", img)\n",
    "# plt.show()\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0448603630065918\n"
     ]
    }
   ],
   "source": [
    "for image_path in test_images:\n",
    "    image_path = \"00298.jpg\"\n",
    "    img = cv2.imread(path + image_path)\n",
    "    og_img = img.copy()\n",
    "\n",
    "    start_time = time.time()\n",
    "    img = red_color_seg(img)\n",
    "    time = time.time() - start_time\n",
    "    print(time)\n",
    "\n",
    "\n",
    "    cir_img = circle_seg(img.copy())\n",
    "    tria_img = tria_seg(img.copy())\n",
    "    cv2.imwrite(\"circle.jpg\", cir_img)\n",
    "    cv2.imwrite(\"tria.jpg\", tria_img)\n",
    "    results_image = np.hstack((tria_img, cir_img, og_img))\n",
    "    image_rgb = cv2.cvtColor(results_image, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"Side by Side\", image_rgb)\n",
    "    # plt.show()\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
